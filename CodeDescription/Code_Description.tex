\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{mathtools,amssymb,amsthm}
\usepackage{lipsum}
\usepackage{hyperref}
\hypersetup{
  unicode=true,
  urlcolor=purple
}
\usepackage{graphicx}

\title{Code description by scripts}
\author{Jose Ruiz}
\date{22 May 2015}

\begin{document}

\maketitle

\section*{Glossary}
\textbf{MiniTree definition}: I'll refer to \textbf{MiniTree} to the tree built with python scripts containing minimal information for N-1 plots, analysis selection optimization and plotting. Constructed from analysis code results.

\textbf{Analysis code}: When I refer to analysis code it's meant the analysis run with extractor. This code is here:  /sps/cms/ruizalva/SL6/CMSSW\_5\_3\_18/src/Extractors/\\PatExtractor/plugins/SingleTprime\_analysis.cc. This code takes as input the extractor results and builds up four trees:
\begin{itemize}
\item \textit{stp}: Analysis tree, corresponding to the signal sample.
\item \textit{stp3LNC}: Control sample
\item \textit{cuts}: For N-1 plots on the preselection cuts
\item \textit{NC}: Tree keeping the number of combinations used on the control sample
\end{itemize}

\textbf{Dominant backgrounds}: It refers to TTJets, QCD HT 500 to 1000, and QCD HT to inf MC samples

\textbf{Subdominant backgrounds}: It refers to QCD PT hat samples, single top, diboson and DY to cc and DY to bb.

\textbf{MC signal samples}: Refers to MC signal samples for all mass points.

\section{Common utilities}

There is two python scripts with common utilities used in several notebooks and other python scripts. 

\begin{itemize}
\item \textbf{Generic.py}: Imports ROOT library and needed python libraries as \textit{numpy} or \textit{array}. Also imports \textit{PUR.C} for the definition of the PU reweighting function \textit{PUR\_function} and used weights. Defines weights for different MC samples and file names. Defines also a generic function \textit{SetAxis} to change axis settings on histograms, and \textit{SetCos} to set cosmetics of histograms: fill color, line color, line width...
\item \textbf{PUR.C}: Definition of PU reweighting utilities. In order to apply the weights a C function is needed, no python function can be passed in a TCut object.
\item \textbf{rootnotes.py}: Utilities for plotting using pyroot
\end{itemize}

\section{Matching efficiency}

The matching efficiency is performed in the notebook \textbf{Matching\_Efficiencies.ipynb} First cells are for exclusive matching efficiency per mass point, then inclusive efficiency is calculated. Both efficiencies are stored in python lists and the plotted at the end of the notebook.

\section{GEN information}

To extract the T' width at GEN level the scrip used is: \textbf{PyScripts/DecayExtractor.py}. It extracts such information directly from \textit{Extractor} trees, specifically \textit{MC} tree asking for the T' PDG id \textit{6000006} and with ``3'' status. Produces a pdf with the width of the T' for each mass point.

\section{T' width after decay}

To extract the T' width after decay from matched jets to MC truth:\\ \textbf{PyScripts/DecayExtractor\_FromMatching.py}. It finds in the \textit{stp} tree, created with the analysis code, the matched jets for the Higgs, W and top and plot from the lorentz vector sum the T' mass. It writes to a root file such mass for each mass point.

\section{Plotting GEN width vs T' width after decay vs reconstructed width}

The plotting of three widths (GEN, decayed T' from MC truth and reconstruction with $\chi^{2}$ sorting algorithm) is done in the notebook \textbf{Histogram\_drawer.ipynb} in the last two cells. It creates a pdf file with a plot per page for the three widths for each mass point. The plotting is done via a generic function to plot histograms from root files containing purely histograms defined in \textbf{HistoOverDrawerFromHistoFile.py}

\section{Higgs Braching ratios}

All possible Higgs branching ratios are drawn in \textbf{Histogram\_drawer.ipynb} for all MC signal samples before trigger in the cell entitled \textit{Plotting BR's}. The information is stored in the \textit{cuts} tree, from analysis code output, under the variable \textit{HiggsProductsBT}. Same info after trigger is also stored in the variable \textit{HiggsProductsAT}.

\section{Creation of MiniTrees}

MiniTrees are stored in numpy arrays to facilitate the reading in other python script or ipython notebooks.

\subsection{For N-1 plots at preselection}
\label{nm1minitrees}

Construction of MiniTrees containing variables that need to be compared at preselection is done in various scripts:
\begin{itemize}
\item \textbf{PyScripts/NumpyNm1ArraysConstructor.py}: For dominant backgrounds, MC signal samples and data.
\item \textbf{PyScripts/NumpyArraysConstructor\_SubdominantBKGS.py}: For subdominant backgrounds
\end{itemize}
Finally, there is also a MiniTree built for validation of SF application done with \textbf{PyScripts/NumpyNm1SFArraysConstructor.py} with the functions to recalculate weights from SF's defined in \textbf{PyScripts/BTagSFtoWeigths.py}. \textit{Under validation}

\subsection{For selection optimization after reconstruction}
\label{selminitrees}

Construction of MiniTrees containing variables that need to optimize the selection after reconstruction, background estimation from data and final selection, is done in various scripts:
\begin{itemize}
\item \textbf{PyScripts/NumpyArraysConstructor.py}: For dominant backgrounds, MC signal samples and data.
\item \textbf{PyScripts/NumpyArraysConstructor\_SubdominantBKGS.py}: For subdominant backgrounds
\end{itemize}

\section{Leading jets pt right after trigger cut}

\textbf{PyScripts/JetsExtractor.py} builds root files with the pt and eta histograms from the 6 leading jets right after trigger selection for all MC signal samples. Plotting to a pdf file is done in the notebook \textbf{Histogram\_drawer.ipynb} in cells entitled \textit{Drawing eta of objects} and \textit{Drawing pt of objects}. 

\section{Resonances (W, H and top) information}

\textbf{PyScripts/JetsResonances.py} builds root files with the pt, eta and mass histograms from the resonances of MC signal samples after reconstruction without HT cut. Plotting to a pdf file is done in the notebook \textbf{Histogram\_drawer.ipynb} in cells entitled \textit{Drawing eta of objects} and \textit{Drawing pt of objects} and \textit{Drawing masses of resonances, right after reconstruction (No HT cut)}. 

\section{N-1 plots at preselection}

The plots for pt and eta of 6 leading jets, Number of vertices and HT are produced in the ipython notebook \textbf{Preselection\_Nminus1.ipynb} from cell entitled \textit{Alternative start of the notebook, to run over constructed npy arrays from last analysis version}. Takes as inputs the MiniTree created in \ref{nm1minitrees}.

\section{Selection after reconstruction optimization}

The optimization of event selection based on the reconstructed objects is done in the notebook \textbf{Selection\_Optimization.ipynb}:
\begin{itemize}
\item First cell to import packages.
\item Second cell takes as input the MiniTrees created in \ref{selminitrees}.
\item Scan over variables performed in third cell producing a pdf for M5J for ttbar QCD HT 500 and 700 GeV signal mass point for the scan. The long list of values produced as output can be used to calculate the expected limits with THETA at lyoserv in the script /gridgroup/cms/jruizalv/WA/LatestExtra/CMSSW\_5\_3\_18/src/theta/\\Tprime/Optimization.py replacing python list called \textit{A}. To launch THETA calculation one should execute \textbf{../utils2/theta\-auto.py Optimization.py}
\item Fourth cell finds the cut for which $S/B$ is highest with ttbar as only background, the minimum QCD and highest $S/B$ taking into account also QCD. 
\item In fifth cell the best cut is set and N-1 plots for ttbar, QCD HT 500 and 700 GeV mass point are produced. Efficiencies, $S/B$, $S/\sqrt{S+B}$ and yields per cut are calculated.
\item In last two cells HT cut is shuffled to be applied at the end and efficiencies, estimators and yields are recalculated. In addition, gaussian fit of the signal is performed cut per cut for all MC signal samples.
\end{itemize}

\section{Study on minimal b-tags requirement}

A study to determine which combination between 3 working points for CSV to select at least 3 b-tags was performed in notebook \textbf{Number\_Of\_Btags\_Study.ipynb}. 
\begin{itemize}
\item First cell: import of packages
\item Second cell: Setting different combinations between working points to select 3 b-tags and counting number of events passing each cuts for ttbar, QCD HT 500 and 700 GeV signal mass point. 
\item Third cell: Printing results from cell 2
\item Fourth cell: Saving results from cell 2 in a numpy array
\item Fifth cell: Calculating efficiencies for each cut for all MC signal samples, calculation of $S/B$ and $S/\sqrt{S+B}$ using ttbar and QCD 500 as backgrounds.
\end{itemize}

\section{Analysis code: /sps/cms/ruizalva/SL6/CMSSW\_5\_3\_18\\/src/Extractors/PatExtractor/plugins/\\SingleTprime\_analysis.cc}

Code has three main trees:
\begin{itemize}
\item m\_tree\_stp: Signal Sample (stp tree)
\item m\_tree\_cuts: N-1 on signal sample (cuts tree)
\item m\_tree\_stp\_3LNC: Control Sample (3LNC tree)
\end{itemize}

Code contained several parts for checks and to explore different variables, characteristics of signal or bkg, etc. The great majority of this parts have been commented to not run in \today~version. I kept variables that I'm not strictly using right now but that can be useful, asked for, afterward, for example b-jets pt.

\subsection{Description by lines}
\begin{itemize}
\item Line 67-81: Definition of Higgs, W and top mass and width for $\chi^{2}$ reconstruction.
\item Line 96-138: Initialization of Lorentz vectors to be included in trees
\item Line 145-148: Definition of tree
\item Line 152-385: Declaration of branches included in stp and 3LNC tree
\item Line 414-468: Declaration of branches included cuts tree
\item Line 472-546: Reading info from python config file
\item Line 554-2314: Main function filling up cuts and stp trees
  \begin{itemize}
  \item 558-565: Part to calculate the acceptance of signal before trigger
  \item 568-608: Obtaining Higgs decay channels before trigger
  \item 610-645: Trigger evaluation and trigger cut
  \item 648-649: Retrieving number of vertices and number of true interactions
  \item 653-807: Retrieving jets characteristics as number of CSVL, CSVM, CSVT, jet multiplicity with $\eta<2.5$, jet multiplicity with $\eta<5$, scale factors.
  \item 837-842: Jet multiplicity with $\eta<2.5$, jet multiplicity with $\eta<5$ cut
  \item 849-858: Leading jet pt cut
  \item 903-907: HT cut
  \item 913-941: Number of b-jets cut
  \item 960-1056: Retrieve scale factors and weight. 1011-1040: Part to retrieve SF's for b-tagging systematics.
  \item 1068-1160: PDF systematics (To be reactivated for PDF systematics on signal)
  \item 1169-1310: $\chi^{2}$ reconstruction
  \item 2063-2245: Partons to jets matching
  \end{itemize}
\item Line 2320-2755: Main function filling up 3NLC tree
  \begin{itemize}
  \item 2323-2342: Trigger evaluation and trigger cut
  \item 2346-2417: Retrieving jets characteristics as number of CSVL, CSVM, CSVT, jet multiplicity with $\eta<2.5$, jet multiplicity with $\eta<5$, scale factors
  \item 2423-2426: Jet multiplicity with $\eta<2.5$, jet multiplicity with $\eta<5$ cut
  \item 2433-2444: Leading jet pt cut
  \item 2468-2469: HT cut
  \item 2476-2478: Number of b-jets cut
  \item 2543-2748: $\chi^{2}$ reconstruction keeping all combinations
  \end{itemize}
\item Line 2761-2789: Functions to do selections over jets, check minimal pt, $\eta$ regions, etc.
\item Line 2081-2872: Main analysis function
\item Line 2878-3007: Functions to retrieve MC truth information
\end{itemize}

\subsection{Turning the code}

Go to PatExtractor/test and set Analysis.py config file:
\begin{itemize}
\item Lines 8,10,11: Values of the Loosee Medium and Tight working points
\item Line 13: Activate jet selection (Jet multiplicity with $\eta<2.5$, jet multiplicity with $\eta<5$ cut)
\item Line 14: Activate Leading jet pt cut
\item Line 15: Activate HT cut
\item Line 16: Activate b-tag multiplicity cut
\item Line 38: Set value cut on jets with $\eta<2.5$
\item Line 39: Set value cut on jets with $\eta<5$
\item Line 40: Set value to cut on leading jet pt.
\item Line 41: Set value to cut on HT.
\item Line 42: Set value to cut b-tag multiplicity.
\item Line 73: Activate mathching, for reconstruction efficiency
\item Line 74: Activate $\chi^{2}$ reconstruction procedure
\end{itemize}

Then to run over data:
\begin{verbatim}
python RunMany_OnlyAnlaysis_DATA_ccage.py
\end{verbatim}
Creates a folder \textit{Workplace\_Data\_\*} with the results.

To run over MC:
\begin{verbatim}
python RunMany_OnlyAnlaysis_MC_ccage.py
\end{verbatim}
Creates a folder \textit{Workplace\_\*} with the results.

Scripts needed in the PatExtractor/test folder:
\begin{itemize}
\item SingleTprime\_DATA\_Template.py: Template python config file to run over data
\item SingleTprime\_MC\_Template.py: Template python config file to run on MC
\item batchJob\_MC3.sh: bash template file to be launched on the queue system. Also reads the config file /afs/in2p3.fr/home/r/ruizalva/5318\_sl6.sh (Copied also in /afs/in2p3.fr/home/r/ruizalva/public/)
\item triggers\_jets.xml: Trigger setting
\end{itemize}

To retrieve and merge Data results:
\begin{verbatim}
pyhton FileMoverCCAGE_full.py Version Workplace
\end{verbatim}where \textit{Workplace} is the directory created by \textit{RunMany\_OnlyAnlaysis\_DATA\_ccage.py} and \textit{Version} is the desired name of the string.

To retrieve and merge MC results:
\begin{verbatim}
pyhton FileMoverCCAGE_data.py Version Workplace
\end{verbatim}where \textit{Workplace} is the directory created by \textit{RunMany\_OnlyAnlaysis\_MC\_ccage.py} and \textit{Version} is the desired name of the string, it can be the same name as for data version. 

These two steps create a \textit{Version} folder in PatExtractor/bin folder. These files are used as input to create the minitrees. 

To create the minitrees the scripts are in PatExtractor/bin/PyScripts. To run any of them one should do, for example:
\begin{verbatim}
python NumpyNm1ArraysConstructor.py
\end{verbatim}

\begin{itemize}
\item Line 5: Basic path to be set (Where root merged versions are located
\item Line 132: Version to process
\item Line 137: Minitrees for MC
\item line 139: Minitrees for DATA. Is divided in parts to accelerate the running. One can copy in various directories and launch in parallel the minitrees construction. To don't duplicate events one must set line 141.
\end{itemize}

Minitrees are lighter than root files from the analysis, and plotting is faster. I then copy the minitrees (.npy files) to my laptop.

To run the preselection data-MC comparison:
\begin{itemize}
\item Copy on local:
\begin{verbatim}
https://github.com/jotadram6/stp-ipy-note/blob/master/Preselection_Nminus1.ipynb
\end{verbatim}
\item Start the notebook running at cell entitled \textit{Alternative start of the notebook, to run over constructed npy arrays from last analysis version} (cell 11)
\item Cell 11: Reading minitrees. PyScripts/SignalSample\_preselectionV1.npy for Signal and dominant backgrounds. PyScripts/SubBKGMC\_preselection\_V1.npy for subdominant backgrounds. PyScripts/Data\_preselectionV1.npy for data. 
\item Cell 12: Cuts and weights
\item Cell 13: Plotting
\end{itemize}

\section*{How to run ipython notebook}

In order to run an ipython notebook one should launch: \textit{ipython notebook} from the folder where the notebooks are located. This opens a browser with all the notebooks, then one should click over the notebook of interest that will be opened in a different browser tab. Ipython notebooks are structured by cells, and they can be run in any order. To run a specific cell one just have to locate the cursor over the cell and do \textit{shift + enter}.  

\end{document}
